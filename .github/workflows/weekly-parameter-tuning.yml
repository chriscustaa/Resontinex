name: weekly-parameter-tuning
on:
  schedule:
    # Run every Sunday at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      force_pr:
        description: 'Force PR creation even if no improvements found'
        type: boolean
        default: false

jobs:
  parameter-optimization:
    name: Weekly Parameter Optimization
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
        
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        pip install -e .[dev]
        
    - name: Download performance baseline
      uses: actions/download-artifact@v4
      continue-on-error: true
      with:
        name: performance-baseline-main
        path: ./baseline/
        
    - name: Run parameter optimization analysis
      id: optimization
      run: |
        echo "::group::Parameter Optimization Analysis"
        
        mkdir -p optimization-results
        
        # Run parameter optimization using existing fusion_ops modules
        python -c "
        import json
        import os
        from datetime import datetime
        from fusion_ops.performance_comparison import PerformanceComparator
        from fusion_ops.budget_analysis import BudgetAnalyzer
        from fusion_ops.metrics import get_metrics_collector
        
        # Initialize analyzers
        comparator = PerformanceComparator()
        budget_analyzer = BudgetAnalyzer()
        metrics_collector = get_metrics_collector()
        
        # Load current overlay parameters
        current_overlay_path = 'configs/fusion/overlay_params.json'
        if os.path.exists(current_overlay_path):
            with open(current_overlay_path, 'r') as f:
                current_params = json.load(f)
        else:
            current_params = {
                'temperature': 0.7,
                'max_tokens': 2048,
                'top_p': 0.9,
                'frequency_penalty': 0.1,
                'presence_penalty': 0.1
            }
        
        # Parameter optimization candidates
        optimization_candidates = []
        
        # Temperature optimization
        temp_variants = [0.6, 0.65, 0.7, 0.75, 0.8]
        for temp in temp_variants:
            if temp != current_params.get('temperature', 0.7):
                latency_impact = (temp - 0.7) * 50  # Higher temp = slightly higher latency
                quality_impact = min(0.05, abs(temp - 0.7) * 0.1)  # Optimal around 0.7
                
                candidate = {
                    'parameter': 'temperature',
                    'current_value': current_params.get('temperature', 0.7),
                    'proposed_value': temp,
                    'estimated_latency_change_ms': latency_impact,
                    'estimated_quality_change': quality_impact,
                    'confidence': 0.8
                }
                optimization_candidates.append(candidate)
        
        # Max tokens optimization
        token_variants = [1024, 1536, 2048, 2560, 3072]
        for tokens in token_variants:
            if tokens != current_params.get('max_tokens', 2048):
                token_ratio = tokens / 2048
                latency_impact = (token_ratio - 1) * 200  # More tokens = higher latency
                cost_impact = (token_ratio - 1) * 15  # More tokens = higher cost
                
                candidate = {
                    'parameter': 'max_tokens',
                    'current_value': current_params.get('max_tokens', 2048),
                    'proposed_value': tokens,
                    'estimated_latency_change_ms': latency_impact,
                    'estimated_cost_change_pct': cost_impact,
                    'confidence': 0.9
                }
                optimization_candidates.append(candidate)
        
        # Filter to top recommendations
        best_candidates = []
        for candidate in optimization_candidates:
            # Score based on estimated improvements and confidence
            score = 0
            
            if 'estimated_latency_change_ms' in candidate:
                if candidate['estimated_latency_change_ms'] < 0:  # Improvement
                    score += abs(candidate['estimated_latency_change_ms']) * 0.1
                else:  # Regression
                    score -= candidate['estimated_latency_change_ms'] * 0.2
            
            if 'estimated_quality_change' in candidate:
                score += candidate['estimated_quality_change'] * 100
                
            if 'estimated_cost_change_pct' in candidate:
                if candidate['estimated_cost_change_pct'] < 0:  # Cost reduction
                    score += abs(candidate['estimated_cost_change_pct']) * 2
                else:  # Cost increase
                    score -= candidate['estimated_cost_change_pct'] * 1.5
            
            score *= candidate.get('confidence', 1.0)
            
            if score > 5:  # Threshold for recommendation
                candidate['optimization_score'] = score
                best_candidates.append(candidate)
        
        # Sort by optimization score
        best_candidates.sort(key=lambda x: x['optimization_score'], reverse=True)
        
        # Take top 3 recommendations
        recommendations = best_candidates[:3]
        
        optimization_result = {
            'timestamp': datetime.utcnow().isoformat() + 'Z',
            'current_parameters': current_params,
            'recommendations': recommendations,
            'analysis_metadata': {
                'candidates_evaluated': len(optimization_candidates),
                'recommendations_count': len(recommendations)
            }
        }
        
        # Save optimization results
        with open('optimization-results/parameter-optimization.json', 'w') as f:
            json.dump(optimization_result, f, indent=2)
        
        print(f'Parameter optimization complete: {len(recommendations)} recommendations')
        
        if recommendations:
            print('TOP_RECOMMENDATION=True')
            best_rec = recommendations[0]
            print(f'BEST_PARAM={best_rec[\"parameter\"]}')
            print(f'BEST_VALUE={best_rec[\"proposed_value\"]}')
            print(f'OPTIMIZATION_SCORE={best_rec[\"optimization_score\"]:.2f}')
        else:
            print('TOP_RECOMMENDATION=False')
            print('No significant optimization opportunities found')
        " 2>&1 | tee optimization_analysis_output.txt
        
        # Extract results for next steps
        if grep -q "TOP_RECOMMENDATION=True" optimization_analysis_output.txt; then
          echo "has_recommendations=true" >> $GITHUB_OUTPUT
          best_param=$(grep "BEST_PARAM=" optimization_analysis_output.txt | cut -d'=' -f2)
          best_value=$(grep "BEST_VALUE=" optimization_analysis_output.txt | cut -d'=' -f2)
          opt_score=$(grep "OPTIMIZATION_SCORE=" optimization_analysis_output.txt | cut -d'=' -f2)
          
          echo "best_parameter=$best_param" >> $GITHUB_OUTPUT
          echo "best_value=$best_value" >> $GITHUB_OUTPUT
          echo "optimization_score=$opt_score" >> $GITHUB_OUTPUT
          echo "âœ… Optimization recommendations generated"
        else
          echo "has_recommendations=false" >> $GITHUB_OUTPUT
          echo "â„¹ï¸ No significant optimizations found"
        fi
        
        echo "::endgroup::"
        
    - name: Create optimization branch
      if: steps.optimization.outputs.has_recommendations == 'true' || github.event.inputs.force_pr == 'true'
      run: |
        echo "::group::Creating Optimization Branch"
        
        optimization_date=$(date +%Y-%m-%d)
        branch_name="auto/parameter-optimization-$optimization_date"
        
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        git checkout -b "$branch_name"
        echo "branch_name=$branch_name" >> $GITHUB_ENV
        
        echo "âœ… Created branch: $branch_name"
        echo "::endgroup::"
        
    - name: Apply parameter optimizations
      if: steps.optimization.outputs.has_recommendations == 'true'
      run: |
        echo "::group::Applying Parameter Optimizations"
        
        # Apply the top recommendation
        python -c "
        import json
        import os
        
        # Load optimization results
        with open('optimization-results/parameter-optimization.json', 'r') as f:
            results = json.load(f)
        
        if not results['recommendations']:
            print('No recommendations to apply')
            exit(0)
        
        # Load current parameters
        overlay_params_path = 'configs/fusion/overlay_params.json'
        if os.path.exists(overlay_params_path):
            with open(overlay_params_path, 'r') as f:
                current_params = json.load(f)
        else:
            current_params = {}
        
        # Apply top recommendation
        top_rec = results['recommendations'][0]
        param_name = top_rec['parameter']
        new_value = top_rec['proposed_value']
        
        print(f'Applying optimization: {param_name} = {new_value}')
        
        # Update parameters
        current_params[param_name] = new_value
        
        # Add optimization metadata
        if 'optimization_history' not in current_params:
            current_params['optimization_history'] = []
        
        current_params['optimization_history'].append({
            'timestamp': results['timestamp'],
            'parameter': param_name,
            'previous_value': top_rec['current_value'],
            'new_value': new_value,
            'optimization_score': top_rec['optimization_score'],
            'confidence': top_rec.get('confidence', 1.0)
        })
        
        # Keep only last 10 optimization history entries
        current_params['optimization_history'] = current_params['optimization_history'][-10:]
        
        # Ensure directory exists
        os.makedirs(os.path.dirname(overlay_params_path), exist_ok=True)
        
        # Save updated parameters
        with open(overlay_params_path, 'w') as f:
            json.dump(current_params, f, indent=2)
        
        print(f'âœ… Parameters updated in {overlay_params_path}')
        "
        
        echo "::endgroup::"
        
    - name: Commit changes
      if: steps.optimization.outputs.has_recommendations == 'true' || github.event.inputs.force_pr == 'true'
      run: |
        git add optimization-results/
        git add configs/fusion/overlay_params.json
        
        optimization_date=$(date +%Y-%m-%d)
        
        if [ "${{ steps.optimization.outputs.has_recommendations }}" == "true" ]; then
          git commit -m "chore: weekly parameter optimization $optimization_date" \
            -m "Optimized ${{ steps.optimization.outputs.best_parameter }} to ${{ steps.optimization.outputs.best_value }}" \
            -m "Optimization score: ${{ steps.optimization.outputs.optimization_score }}" \
            -m "Auto-generated by weekly parameter tuning workflow"
        else
          git commit -m "chore: weekly parameter optimization $optimization_date" \
            -m "No significant optimizations found - updating analysis results only" \
            -m "Auto-generated by weekly parameter tuning workflow"
        fi
        
        git push origin "${{ env.branch_name }}"
        
    - name: Create PR title and body files
      if: steps.optimization.outputs.has_recommendations == 'true' || github.event.inputs.force_pr == 'true'
      run: |
        # Create PR title file
        if [ "${{ steps.optimization.outputs.has_recommendations }}" == "true" ]; then
          echo "ðŸŽ¯ Weekly Parameter Optimization: ${{ steps.optimization.outputs.best_parameter }} â†’ ${{ steps.optimization.outputs.best_value }}" > pr_title.txt
        else
          echo "ðŸ“Š Weekly Parameter Analysis - No Optimizations" > pr_title.txt
        fi
        
        # Create PR body file
        echo "## ðŸŽ¯ Weekly Parameter Optimization" > pr_body.md
        echo "" >> pr_body.md
        echo "**Analysis Complete:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> pr_body.md
        echo "" >> pr_body.md
        echo "### ðŸ“Š Summary" >> pr_body.md
        
        if [ "${{ steps.optimization.outputs.has_recommendations }}" == "true" ]; then
          echo "Parameter optimization analysis identified improvement opportunities." >> pr_body.md
          echo "" >> pr_body.md
          echo "**Recommended Changes:**" >> pr_body.md
          echo "- Parameter: \`${{ steps.optimization.outputs.best_parameter }}\`" >> pr_body.md
          echo "- Proposed Value: \`${{ steps.optimization.outputs.best_value }}\`" >> pr_body.md
          echo "- Optimization Score: ${{ steps.optimization.outputs.optimization_score }}" >> pr_body.md
          echo "" >> pr_body.md
          echo "### âœ… Next Steps" >> pr_body.md
          echo "1. Review the proposed parameter changes" >> pr_body.md
          echo "2. Run integration tests to validate performance impact" >> pr_body.md
          echo "3. Monitor fusion effectiveness after merge" >> pr_body.md
        else
          echo "No significant optimization opportunities found. Current overlay parameters appear to be performing optimally based on recent metrics." >> pr_body.md
          echo "" >> pr_body.md
          echo "### ðŸ“ˆ Current Performance" >> pr_body.md
          echo "Analysis indicates that existing parameters are well-tuned for current workloads." >> pr_body.md
        fi
        
        echo "" >> pr_body.md
        echo "---" >> pr_body.md
        echo "*Auto-generated by RESONTINEX Weekly Parameter Tuning*" >> pr_body.md
        
    - name: Create pull request
      if: steps.optimization.outputs.has_recommendations == 'true' || github.event.inputs.force_pr == 'true'
      run: |
        # Read title and body from files
        PR_TITLE=$(cat pr_title.txt)
        PR_BODY=$(cat pr_body.md)
        
        # Create PR using GitHub CLI
        gh pr create \
          --title "$PR_TITLE" \
          --body "$PR_BODY" \
          --head "${{ env.branch_name }}" \
          --base main
        
        # Add appropriate labels
        if [ "${{ steps.optimization.outputs.has_recommendations }}" == "true" ]; then
          gh pr edit --add-label optimization,automated,parameter-tuning
        else
          gh pr edit --add-label analysis,automated,no-change
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Upload optimization artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: parameter-optimization-${{ github.run_number }}
        path: |
          optimization-results/
          optimization_analysis_output.txt
          pr_title.txt
          pr_body.md
        retention-days: 30